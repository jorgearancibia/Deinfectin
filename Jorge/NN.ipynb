{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de zapatos usando regresión logística y NN\n",
    "\n",
    "Mediante el uso de redes neuronales se planea generar un algoritmo que permita discriminar si una imagen corresponde a un zapato o no.\n",
    "\n",
    "#### Librerías a utilizar\n",
    "\n",
    "- [Numpy](www.numpy.org) Paquete fundamental para computación científica en Python.\n",
    "- [matplotlib](http://matplotlib.org) Librería muy utilizada para generar gráficas.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) y [scipy](https://www.scipy.org/) son usados para testear el algoritmo al final con cualquier foto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s(z):\n",
    "    '''\n",
    "    Función sigmoide\n",
    "    '''\n",
    "    \n",
    "    output = 1 / (1 + np.exp(-z))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagacion(w, b, X, Y):\n",
    "    '''\n",
    "    Función que calcula el gradiente de la función de costos\n",
    "    '''\n",
    "    m = X.shape[1] # Tamaño del Dataset\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X) + b)                                  \n",
    "    cost = -1/m * np.sum(Y * np.log(A) + (1 - Y)*np.log(1 - A))                              \n",
    "    \n",
    "    # Calculo del gradiente dJ/dw y dJ/db\n",
    "    \n",
    "    dw = (np.dot(X, (A - Y).T)) / m\n",
    "    db = np.sum(A - Y) / m\n",
    "\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizacion(w, b, X, Y, learning_rate, num_iter = 100):\n",
    "    '''\n",
    "    Función que optimiza la función de costo calculando los parámetros b y W que\n",
    "    minimicen J(w, b) usando el método del descenso de gradiente\n",
    "    '''\n",
    "    \n",
    "    m = int(num_iter / 10)\n",
    "    costs = []\n",
    "    \n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        # Computo del costo y del gradiente\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # Actualizamos el valor de w y b\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "         \n",
    "        # Guardamos el costo cada ciertas iteraciones\n",
    "        \n",
    "        if i % m == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    costs = np.array(costs)\n",
    "    \n",
    "    return params, grads, costs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
